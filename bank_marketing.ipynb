{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vz5pN25bKDtA"
   },
   "source": [
    "**Objective:**\n",
    "The goal of this midterm report is to demonstrate your ability to analyze a dataset by explaining its source, relevance, and key characteristics using exploratory data analysis (EDA) techniques, including statistical summaries and visualizations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LSP8AAD2Jy_m"
   },
   "source": [
    "## **Dataset Selection and Explanation**\n",
    "- Clearly specify the dataset you have chosen.\n",
    "- Provide details on its source (e.g., Kaggle, UCI Machine Learning Repository, government open data, etc.).\n",
    "- Describe what the dataset is about (e.g., what kind of information it contains).\n",
    "- Explain why you selected this dataset and why it is interesting or relevant for analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IlW3KR-WJ7wi"
   },
   "source": [
    "ข้อมูลนี้เป็นชุดข้อมูลเกี่ยวกับแคมเปญทางการตลาดของสถาบันการเงินแห่งหนึ่งในประเทศโปรตุเกส ซึ่งแคมเปญการตลาดนี้ใช้การโทรศัพท์ไปยังลูกค้าโดยตรง หลายครั้งที่ต้องติดต่อมากกว่าหนึ่งครั้งกับลูกค้ารายเดียวกัน เพื่อประเมินว่าลูกค้าจะสมัครผลิตภัณฑ์ (เงินฝากประจำของธนาคาร) หรือไม่\n",
    "\n",
    "1. **age** - อายุของลูกค้า  \n",
    "2. **job** - อาชีพของลูกค้า  \n",
    "3. **marital** - สถานะสมรสของลูกค้า  \n",
    "4. **education** - ระดับการศึกษาของลูกค้า  \n",
    "5. **default** - มีประวัติผิดนัดชำระหนี้หรือไม่  \n",
    "6. **housing** - มีสินเชื่อที่อยู่อาศัยหรือไม่  \n",
    "7. **loan** - มีสินเชื่อส่วนบุคคลหรือไม่  \n",
    "8. **contact** - ช่องทางการติดต่อกับลูกค้า  \n",
    "9. **month** - เดือนที่ติดต่อครั้งล่าสุด  \n",
    "10. **day** - วันในสัปดาห์ที่ติดต่อครั้งล่าสุด  \n",
    "11. **duration** - ระยะเวลาของการติดต่อครั้งล่าสุด (วินาที)  \n",
    "12. **campaign** - จำนวนครั้งที่ติดต่อในแคมเปญนี้สำหรับลูกค้ารายนั้น  \n",
    "13. **pdays** - จำนวนวันที่ผ่านไปหลังจากที่ลูกค้าถูกติดต่อครั้งล่าสุดจากแคมเปญก่อนหน้า  \n",
    "14. **previous** - จำนวนครั้งที่เคยติดต่อก่อนแคมเปญนี้สำหรับลูกค้ารายนั้น  \n",
    "15. **poutcome** - ผลลัพธ์ของแคมเปญการตลาดก่อนหน้า  \n",
    "16. **emp.var.rate** - อัตราการเปลี่ยนแปลงของการจ้างงาน  \n",
    "17. **cons.price.idx** - ดัชนีราคาผู้บริโภค  \n",
    "18. **cons.confidx** - ดัชนีความเชื่อมั่นของผู้บริโภค  \n",
    "19. **euribor3m** - อัตราดอกเบี้ยยูริบอร์ (Euribor) ระยะเวลา 3 เดือน  \n",
    "20. **nr.employed** - จำนวนพนักงานในระบบเศรษฐกิจ  \n",
    "21. **y** - ลูกค้าสมัครฝากเงินแบบมีกำหนดระยะเวลาหรือไม่ (เป้าหมายของแคมเปญ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FMwvSTmujA20"
   },
   "source": [
    "**Business requirements** <br>\n",
    "- พัฒนาปรับปรุงแคมเปญ เพื่อการเพิ่มขึ้นของอัตราความสำเร็จของแคมเปญ (ลูกค้าสมัครผลิตภัณฑ์) ex. แผนการโทรหาเพื่อให้ลูกค้ามีแนวโน้มตอบตกลงมากขึ้น <br>\n",
    "- การลดต้นทุนและเพิ่มประสิทธิภาพของแคมเปญ => ลดค่าใช้จ่ายในการโทร แต่ลูกค้าก็ยังสมัครเยอะอยู่\n",
    "- สร้างโมเดลคาดการณ์ว่าลูกค้ารายใหม่จะสมัครหรือไม่ <br>\n",
    "- Customer Segment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-g9ngZiQG-HC"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pSgW4KftHQQT"
   },
   "source": [
    "## **Import Bank Marketing Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 431
    },
    "id": "2IBCEu8uP8yA",
    "outputId": "db5f99b0-a7b3-4ec9-cd73-43183a1e881b"
   },
   "outputs": [],
   "source": [
    "bank = pd.read_csv(\"bank-additional-full.csv\", sep=';')\n",
    "bank"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rrzj_3FGCREr"
   },
   "source": [
    "## **Data Preparation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OJeyNh_yUkLy"
   },
   "outputs": [],
   "source": [
    "bank = bank.rename(columns={\n",
    "    \"emp.var.rate\": \"emp_variation_rate\",\n",
    "    \"cons.price.idx\": \"cons_price\",\n",
    "    \"cons.confidx\": \"cons_confidence\",\n",
    "    \"euribor3m\": \"euribor_3m\",\n",
    "    \"nr.employed\": \"num_employees\"\n",
    "})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6X0R_4dYKpk1"
   },
   "source": [
    "**Unknown Values**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 231
    },
    "id": "5g18koAPFojj",
    "outputId": "4a99b474-84e1-4026-bc4b-3777bef864c6"
   },
   "outputs": [],
   "source": [
    "unknown_values = (bank == \"unknown\").sum()\n",
    "unknown_df = pd.DataFrame({\"Count of Unknown\": unknown_values.values,\n",
    "                           \"Percent\": (unknown_values.values/bank.count())*100})\n",
    "\n",
    "unknown_df = unknown_df[unknown_df[\"Count of Unknown\"] > 0]\n",
    "unknown_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r816-fk3upSk"
   },
   "source": [
    "### **Replace Unknow value with Mode**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MDwq6i2WCh_N"
   },
   "outputs": [],
   "source": [
    "def fill_unknowns_with_mode(df):\n",
    "    df = df.copy()\n",
    "    for col in [\"job\", \"marital\", \"education\", \"default\", \"housing\", \"loan\"]:\n",
    "        mode_val = df[col].mode()[0]\n",
    "        df[col] = df[col].replace(\"unknown\", mode_val)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gYsf6TzdKN_d"
   },
   "outputs": [],
   "source": [
    "bank_filledMode = fill_unknowns_with_mode(bank)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EDjaWwQsMjZF"
   },
   "source": [
    "### **Replace Unknow value with ML**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NXF2YiY0IDJP"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "def fill_unknowns_with_ml(df: pd.DataFrame, fill_order: list):\n",
    "    df_filled = df.copy()\n",
    "    label_encoders = {}\n",
    "\n",
    "    for target in fill_order:\n",
    "        print(f\"Replace Unknown values in column: {target}\")\n",
    "        known = df_filled[df_filled[target] != 'unknown'].copy()\n",
    "        unknown = df_filled[df_filled[target] == 'unknown'].copy()\n",
    "\n",
    "        if unknown.empty:\n",
    "            continue\n",
    "\n",
    "        # One-hot encoding\n",
    "        full_encoded = pd.get_dummies(df_filled.drop(columns=[target]), drop_first=True)\n",
    "\n",
    "        # Split encoded known/unknown rows\n",
    "        X = full_encoded.loc[known.index]\n",
    "        X_pred = full_encoded.loc[unknown.index]\n",
    "\n",
    "        # Encode target (y)\n",
    "        le = LabelEncoder()\n",
    "        y = le.fit_transform(known[target])\n",
    "        label_encoders[target] = le\n",
    "\n",
    "        # Train and predict\n",
    "        model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "        model.fit(X, y)\n",
    "        y_pred = model.predict(X_pred)\n",
    "        y_pred_labels = le.inverse_transform(y_pred)\n",
    "\n",
    "        df_filled.loc[unknown.index, target] = y_pred_labels\n",
    "    return df_filled\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tny0L6J9IFtS",
    "outputId": "c68991c7-cbde-4198-f31f-e5f4e58a5573"
   },
   "outputs": [],
   "source": [
    "fill_order = [\"marital\", \"job\", \"housing\", \"loan\", \"education\", \"default\"]\n",
    "bank_filledML = fill_unknowns_with_ml(bank, fill_order)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oRdURrHcUmeE"
   },
   "source": [
    "### **Replace Unknow value with MICE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hZrELogAVpNP"
   },
   "outputs": [],
   "source": [
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gh8ftkNO03No"
   },
   "outputs": [],
   "source": [
    "def mice_impute_categorical(data):\n",
    "    df = data.copy()\n",
    "    cat_cols = df.select_dtypes(include=['object', 'category']).columns\n",
    "\n",
    "    # Encode first\n",
    "    encoder = OrdinalEncoder()\n",
    "    df[cat_cols] = encoder.fit_transform(df[cat_cols])\n",
    "\n",
    "    for col in cat_cols:\n",
    "        if df[col].isnull().sum() > 0:\n",
    "            # Prepare training and test set\n",
    "            not_null = df[~df[col].isnull()]\n",
    "            is_null = df[df[col].isnull()]\n",
    "\n",
    "            X_train = not_null.drop([col], axis=1)\n",
    "            y_train = not_null[col]\n",
    "            X_pred = is_null.drop([col], axis=1)\n",
    "\n",
    "            clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "            clf.fit(X_train, y_train)\n",
    "\n",
    "            preds = clf.predict(X_pred)\n",
    "\n",
    "            df.loc[is_null.index, col] = preds\n",
    "\n",
    "    # Decode back to original\n",
    "    df[cat_cols] = encoder.inverse_transform(df[cat_cols])\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EIlEW_chdYxq"
   },
   "outputs": [],
   "source": [
    "bank_filledMICE = mice_impute_categorical(bank)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RHUPycZOPYkj"
   },
   "source": [
    "## **Train Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6WAg-diSTRIL"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_data(df):\n",
    "    num_cols = df.select_dtypes(include=['int64', 'float64']).columns\n",
    "    cat_cols = df.select_dtypes(include='object').columns[:-1]  \n",
    "\n",
    "    encoder = OneHotEncoder(handle_unknown='ignore')\n",
    "    encoded_features = encoder.fit_transform(df[cat_cols]).toarray()\n",
    "\n",
    "    encoded_df = pd.DataFrame(encoded_features, \n",
    "                             columns=encoder.get_feature_names_out(cat_cols),\n",
    "                             index=df.index)\n",
    "\n",
    "    encoded_df = pd.concat([encoded_df, df[num_cols]], axis=1)\n",
    "\n",
    "    le = LabelEncoder()\n",
    "    encoded_df['y'] = le.fit_transform(df['y'])\n",
    "\n",
    "    return encoded_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sAMWbnTv03HE"
   },
   "outputs": [],
   "source": [
    "# 1. Not Replace Unknown value\n",
    "bank_encoded_Unknown = encode_data(bank)\n",
    "y_uk = bank_encoded_Unknown[\"y\"]\n",
    "X_uk = bank_encoded_Unknown.drop(columns = [\"y\"])\n",
    "\n",
    "# 2. Replace Unknown value with ML\n",
    "bank_encoded_ML = encode_data(bank_filledML)\n",
    "y_ml = bank_encoded_ML[\"y\"]\n",
    "X_ml = bank_encoded_ML.drop(columns = [\"y\"])\n",
    "\n",
    "# 3. Replace Unknown value with Mode\n",
    "bank_encoded_Mode = encode_data(bank_filledMode)\n",
    "y_mode = bank_encoded_Mode[\"y\"]\n",
    "X_mode = bank_encoded_Mode.drop(columns = [\"y\"])\n",
    "\n",
    "# 4. Replace Unknown value with MICE\n",
    "bank_encoded_MICE = encode_data(bank_filledMICE)\n",
    "y_mice = bank_encoded_MICE[\"y\"]\n",
    "X_mice = bank_encoded_MICE.drop(columns = [\"y\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ติดตั้งเวอร์ชันที่เข้ากันได้กับ Colab\n",
    "!pip install numpy==2.0.2 pandas==2.2.2 scikit-learn==1.6.1 imbalanced-learn==0.13.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4LSfTsj--fOe"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.base import clone\n",
    "from sklearn.metrics import (\n",
    "    f1_score, accuracy_score, precision_score, recall_score, roc_auc_score,\n",
    "    classification_report, confusion_matrix\n",
    ")\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.pipeline import Pipeline\n",
    "from imblearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import TomekLinks\n",
    "from imblearn.combine import SMOTETomek\n",
    "import time "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lq_ezdbxxVcO"
   },
   "source": [
    "##**Train Model with XGBoost**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install xgboost==2.1.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aTRzyLALFLMu"
   },
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nZ_Pk_oME1UW"
   },
   "outputs": [],
   "source": [
    "def XGBoost_model(X, y, condition):\n",
    "    start_time = time.time()\n",
    "    n_splits = 5\n",
    "\n",
    "    # Parameter grid\n",
    "    param_grid = {\n",
    "        'xgb__n_estimators': [100, 200, 300],\n",
    "        'xgb__max_depth': [3, 6, 12, 20],\n",
    "        'xgb__learning_rate': [0.01, 0.1]\n",
    "    }\n",
    "\n",
    "    # CV\n",
    "    outer_cv = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    inner_cv = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "    accuracies, aucs, conf_matrixs = [], [], []\n",
    "    macro_f1s, macro_precisions, macro_recalls = [], [], []\n",
    "    weighted_f1s, weighted_precisions, weighted_recalls = [], [], []\n",
    "    sensitivities, specificities, balanced_accuracies = [], [], []\n",
    "\n",
    "    for fold_idx, (train_idx, test_idx) in enumerate(outer_cv.split(X, y), start=1):\n",
    "        X_train, X_val = X.iloc[train_idx], X.iloc[test_idx]\n",
    "        y_train, y_val = y.iloc[train_idx], y.iloc[test_idx]\n",
    "\n",
    "        # pipeline\n",
    "        if condition == \"IM\":\n",
    "            pipeline = ImbPipeline([\n",
    "                ('xgb', XGBClassifier(\n",
    "                    use_label_encoder=False,\n",
    "                    eval_metric='logloss',\n",
    "                    random_state=42\n",
    "                    #tree_method='gpu_hist',\n",
    "                    #predictor='gpu_predictor',\n",
    "                    #gpu_id=0\n",
    "                    ))\n",
    "            ])\n",
    "\n",
    "        elif condition == \"SMOTE\":\n",
    "            class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(y_train), y=y_train)\n",
    "            scale_pos_weight = class_weights[0] / class_weights[1]\n",
    "\n",
    "            pipeline = ImbPipeline([\n",
    "                ('smote', SMOTE(random_state=42)),\n",
    "                ('xgb', XGBClassifier(\n",
    "                    use_label_encoder=False,\n",
    "                    eval_metric='logloss',\n",
    "                    random_state=42,\n",
    "                    #tree_method='gpu_hist',\n",
    "                    #predictor='gpu_predictor',\n",
    "                    #gpu_id=0,\n",
    "                    scale_pos_weight=scale_pos_weight))\n",
    "            ])\n",
    "\n",
    "        elif condition == \"TomekLinks\":\n",
    "            class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(y_train), y=y_train)\n",
    "            scale_pos_weight = class_weights[0] / class_weights[1]\n",
    "\n",
    "            pipeline = ImbPipeline([\n",
    "                ('under', TomekLinks()),\n",
    "                ('xgb', XGBClassifier(\n",
    "                    use_label_encoder=False,\n",
    "                    eval_metric='logloss',\n",
    "                    random_state=42,\n",
    "                    #tree_method='gpu_hist',\n",
    "                    #predictor='gpu_predictor',\n",
    "                    #gpu_id=0,\n",
    "                    scale_pos_weight=scale_pos_weight))\n",
    "            ])\n",
    "        elif condition == \"SMOTETomek\":\n",
    "            class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(y_train), y=y_train)\n",
    "            scale_pos_weight = class_weights[0] / class_weights[1]\n",
    "            pipeline = ImbPipeline([\n",
    "                ('resample', SMOTETomek(random_state=42)),\n",
    "                ('xgb', XGBClassifier(\n",
    "                    use_label_encoder=False,\n",
    "                    eval_metric='logloss',\n",
    "                    random_state=42,\n",
    "                    #tree_method='gpu_hist',\n",
    "                    #predictor='gpu_predictor',\n",
    "                    #gpu_id=0,\n",
    "                    scale_pos_weight=scale_pos_weight))\n",
    "            ])\n",
    "\n",
    "        grid_search = GridSearchCV(\n",
    "            estimator=pipeline,\n",
    "            param_grid=param_grid,\n",
    "            scoring='f1',\n",
    "            n_jobs=-1,\n",
    "            error_score='raise'\n",
    "        )\n",
    "\n",
    "\n",
    "        grid_search.fit(X_train, y_train)\n",
    "        best_model = grid_search.best_estimator_\n",
    "\n",
    "        y_pred = best_model.predict(X_val)\n",
    "        y_proba = best_model.predict_proba(X_val)[:, 1]\n",
    "\n",
    "        cm = confusion_matrix(y_val, y_pred)\n",
    "        conf_matrixs.append({\"fold\": fold_idx, \"conf_matrix\": cm})\n",
    "\n",
    "        # Print report\n",
    "        print(f\"\\n=== Classification Report for Fold {fold_idx} ===\")\n",
    "        print(classification_report(y_val, y_pred))\n",
    "\n",
    "        print(f\"Confusion Matrix for Fold {fold_idx}:\")\n",
    "        print(conf_matrixs[fold_idx-1]['conf_matrix'])\n",
    "\n",
    "        print(f\"Best Parameters for Fold {fold_idx}: {grid_search.best_params_}\")\n",
    "\n",
    "        # metrics\n",
    "        accuracies.append(accuracy_score(y_val, y_pred))\n",
    "        aucs.append(roc_auc_score(y_val, y_proba))\n",
    "        macro_f1s.append(f1_score(y_val, y_pred, average='macro'))\n",
    "        macro_precisions.append(precision_score(y_val, y_pred, average='macro'))\n",
    "        macro_recalls.append(recall_score(y_val, y_pred, average='macro'))\n",
    "        weighted_f1s.append(f1_score(y_val, y_pred, average='weighted'))\n",
    "        weighted_precisions.append(precision_score(y_val, y_pred, average='weighted'))\n",
    "        weighted_recalls.append(recall_score(y_val, y_pred, average='weighted'))\n",
    "\n",
    "        sensitivity = recall_score(y_val, y_pred, pos_label=1)\n",
    "        specificity = recall_score(y_val, y_pred, pos_label=0)\n",
    "        balanced_acc = (sensitivity + specificity) / 2\n",
    "\n",
    "        sensitivities.append(sensitivity)\n",
    "        specificities.append(specificity)\n",
    "        balanced_accuracies.append(balanced_acc)\n",
    "\n",
    "    # Summary\n",
    "    results = {\n",
    "        'mean_accuracy': sum(accuracies) / n_splits,\n",
    "        'mean_auc': sum(aucs) / n_splits,\n",
    "        'macro_f1': sum(macro_f1s) / n_splits,\n",
    "        'macro_precision': sum(macro_precisions) / n_splits,\n",
    "        'macro_recall': sum(macro_recalls) / n_splits,\n",
    "        'weighted_f1': sum(weighted_f1s) / n_splits,\n",
    "        'weighted_precision': sum(weighted_precisions) / n_splits,\n",
    "        'weighted_recall': sum(weighted_recalls) / n_splits,\n",
    "        'mean_sensitivity': sum(sensitivities) / n_splits,\n",
    "        'mean_specificity': sum(specificities) / n_splits,\n",
    "        'mean_balanced_accuracy': sum(balanced_accuracies) / n_splits\n",
    "    }\n",
    "\n",
    "    end_time = time.time()\n",
    "    print(f\"\\nTotal training time: {end_time - start_time:.2f} seconds\")\n",
    "\n",
    "    return pd.DataFrame([results])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oF2tJDlKxemv"
   },
   "source": [
    "#### **Imbalanced data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XGB_Unknown_IM = XGBoost_model(X_uk, y_uk, \"IM\")\n",
    "XGB_Unknown_IM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wMAild3GFpXb"
   },
   "outputs": [],
   "source": [
    "XGB_ML_IM = XGBoost_model(X_ml, y_ml, \"IM\")\n",
    "XGB_ML_IM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-3yf1mYHFwXG"
   },
   "outputs": [],
   "source": [
    "XGB_Mode_IM = XGBoost_model(X_mode, y_mode, \"IM\")\n",
    "XGB_Mode_IM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ziaqc7jCJHi1"
   },
   "outputs": [],
   "source": [
    "XGB_MICE_IM = XGBoost_model(X_mice, y_mice, \"IM\")\n",
    "XGB_MICE_IM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C_VyT_TlxmKV"
   },
   "source": [
    "#### **TomekLinks**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XGB_Unknown_TML = XGBoost_model(X_uk, y_uk, \"TomekLinks\")\n",
    "XGB_Unknown_TML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n0tsbDa4F2d7"
   },
   "outputs": [],
   "source": [
    "XGB_ML_TML = XGBoost_model(X_ml, y_ml, \"TomekLinks\")\n",
    "XGB_ML_TML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FcCqTpbfF22Z"
   },
   "outputs": [],
   "source": [
    "########\n",
    "XGB_Mode_TML = XGBoost_model(X_mode, y_mode, \"TomekLinks\")\n",
    "XGB_Mode_TML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "86jmyolcJDR7"
   },
   "outputs": [],
   "source": [
    "XGB_MICE_TML = XGBoost_model(X_mice, y_mice, \"TomekLinks\")\n",
    "XGB_MICE_TML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iNeyjr80xp2B"
   },
   "source": [
    "#### **SMOTE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XGB_Unknown_SM = XGBoost_model(X_uk, y_uk, \"SMOTE\")\n",
    "XGB_Unknown_SM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1oEG82hYGGs9"
   },
   "outputs": [],
   "source": [
    "XGB_ML_SM = XGBoost_model(X_ml, y_ml, \"SMOTE\")\n",
    "XGB_ML_SM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xMwDDXqNGIKu"
   },
   "outputs": [],
   "source": [
    "XGB_Mode_SM = XGBoost_model(X_mode, y_mode, \"SMOTE\")\n",
    "XGB_Mode_SM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BaRVi_0HI5vE"
   },
   "outputs": [],
   "source": [
    "XGB_MICE_SM = XGBoost_model(X_mice, y_mice, \"SMOTE\")\n",
    "XGB_MICE_SM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EG-1t3ssIv_S"
   },
   "source": [
    "#### **SMOTE + TomekLinks**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XGB_Unknown_SMTML = XGBoost_model(X_uk, y_uk, \"SMOTETomek\")\n",
    "XGB_Unknown_SMTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A4UDpkI3Iv_W"
   },
   "outputs": [],
   "source": [
    "XGB_ML_SMTML = XGBoost_model(X_ml, y_ml, \"SMOTETomek\")\n",
    "XGB_ML_SMTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MyVw7hiXIv_X"
   },
   "outputs": [],
   "source": [
    "XGB_Mode_SMTML = XGBoost_model(X_mode, y_mode, \"SMOTETomek\")\n",
    "XGB_Mode_SMTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NvLGOqhNIv_X"
   },
   "outputs": [],
   "source": [
    "XGB_MICE_SMTML = XGBoost_model(X_mice, y_mice, \"SMOTETomek\")\n",
    "XGB_MICE_SMTML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JT84qNEIvaoC"
   },
   "source": [
    "##**Train Model with Random Forest model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hzmhGNxA75Zv"
   },
   "outputs": [],
   "source": [
    "def RandomForest_model(X, y, condition):\n",
    "    start_time = time.time()\n",
    "    n_splits = 5\n",
    "\n",
    "    # pipeline\n",
    "    if condition == \"IM\":\n",
    "        pipeline = Pipeline([('rf', RandomForestClassifier(random_state=42))])\n",
    "\n",
    "    elif condition == \"SMOTE\":\n",
    "        pipeline = Pipeline([\n",
    "            ('smote', SMOTE(random_state=42)),\n",
    "            ('rf', RandomForestClassifier(random_state=42, class_weight='balanced'))\n",
    "        ])\n",
    "\n",
    "    elif condition == \"TomekLinks\":\n",
    "        pipeline = Pipeline([\n",
    "            ('under', TomekLinks()),\n",
    "            ('rf', RandomForestClassifier(random_state=42, class_weight='balanced'))\n",
    "        ])\n",
    "\n",
    "    elif condition == \"SMOTETomek\":\n",
    "        pipeline = Pipeline([\n",
    "            ('resample', SMOTETomek(random_state=42)),\n",
    "            ('rf', RandomForestClassifier(random_state=42, class_weight='balanced'))\n",
    "        ])\n",
    "\n",
    "    # Parameter grid\n",
    "    param_grid = {\n",
    "        'rf__n_estimators': [200, 300, 500],\n",
    "        'rf__max_depth': [None, 10, 15],\n",
    "        'rf__min_samples_split': [2, 5]\n",
    "    }\n",
    "\n",
    "    # CV\n",
    "    outer_cv = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    inner_cv = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "    accuracies, aucs, conf_matrixs = [], [], []\n",
    "    macro_f1s, macro_precisions, macro_recalls = [], [], []\n",
    "    weighted_f1s, weighted_precisions, weighted_recalls = [], [], []\n",
    "    sensitivities, specificities, balanced_accuracies = [], [], []\n",
    "\n",
    "    for fold_idx, (train_idx, test_idx) in enumerate(outer_cv.split(X, y), start=1):\n",
    "        X_train, X_val = X.iloc[train_idx], X.iloc[test_idx]\n",
    "        y_train, y_val = y.iloc[train_idx], y.iloc[test_idx]\n",
    "\n",
    "        grid_search = GridSearchCV(\n",
    "            estimator=clone(pipeline),\n",
    "            param_grid=param_grid,\n",
    "            cv=inner_cv,\n",
    "            scoring=\"f1\",\n",
    "            n_jobs=-1\n",
    "        )\n",
    "        grid_search.fit(X_train, y_train)\n",
    "        best_model = grid_search.best_estimator_\n",
    "\n",
    "        y_pred = best_model.predict(X_val)\n",
    "        y_proba = best_model.predict_proba(X_val)[:, 1]\n",
    "        cm = confusion_matrix(y_val, y_pred)\n",
    "        conf_matrixs.append({\"fold\": fold_idx, \"conf_matrix\": cm})\n",
    "\n",
    "        # Print report\n",
    "        print(f\"\\n=== Classification Report for Fold {fold_idx} ===\")\n",
    "        print(classification_report(y_val, y_pred))\n",
    "\n",
    "        print(f\"Confusion Matrix for Fold {fold_idx}:\")\n",
    "        print(conf_matrixs[fold_idx-1]['conf_matrix'])\n",
    "        \n",
    "        print(f\"Best Parameters for Fold {fold_idx}: {grid_search.best_params_}\")\n",
    "\n",
    "        # metrics\n",
    "        accuracies.append(accuracy_score(y_val, y_pred))\n",
    "        aucs.append(roc_auc_score(y_val, y_proba))\n",
    "        macro_f1s.append(f1_score(y_val, y_pred, average='macro'))\n",
    "        macro_precisions.append(precision_score(y_val, y_pred, average='macro'))\n",
    "        macro_recalls.append(recall_score(y_val, y_pred, average='macro'))\n",
    "        weighted_f1s.append(f1_score(y_val, y_pred, average='weighted'))\n",
    "        weighted_precisions.append(precision_score(y_val, y_pred, average='weighted'))\n",
    "        weighted_recalls.append(recall_score(y_val, y_pred, average='weighted'))\n",
    "\n",
    "        sensitivity = recall_score(y_val, y_pred, pos_label=1)\n",
    "        specificity = recall_score(y_val, y_pred, pos_label=0)\n",
    "        balanced_acc = (sensitivity + specificity) / 2\n",
    "\n",
    "        sensitivities.append(sensitivity)\n",
    "        specificities.append(specificity)\n",
    "        balanced_accuracies.append(balanced_acc)\n",
    "\n",
    "    # Summary as DataFrame\n",
    "    results = {\n",
    "        'mean_accuracy': sum(accuracies) / n_splits,\n",
    "        'mean_auc': sum(aucs) / n_splits,\n",
    "        'macro_f1': sum(macro_f1s) / n_splits,\n",
    "        'macro_precision': sum(macro_precisions) / n_splits,\n",
    "        'macro_recall': sum(macro_recalls) / n_splits,\n",
    "        'weighted_f1': sum(weighted_f1s) / n_splits,\n",
    "        'weighted_precision': sum(weighted_precisions) / n_splits,\n",
    "        'weighted_recall': sum(weighted_recalls) / n_splits,\n",
    "        'mean_sensitivity': sum(sensitivities) / n_splits,\n",
    "        'mean_specificity': sum(specificities) / n_splits,\n",
    "        'mean_balanced_accuracy': sum(balanced_accuracies) / n_splits\n",
    "    }\n",
    "    end_time = time.time()\n",
    "    print(f\"\\nTotal training time: {end_time - start_time:.2f} seconds\")\n",
    "\n",
    "    return pd.DataFrame([results])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pCfVzY_mvsoZ"
   },
   "source": [
    "#### **Imbalanced data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RF_Unknown_IM = RandomForest_model(X_uk, X_uk, \"IM\")\n",
    "RF_Unknown_IM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oCPJDD6JAC78"
   },
   "outputs": [],
   "source": [
    "RF_ML_IM = RandomForest_model(X_ml, y_ml, \"IM\")\n",
    "RF_ML_IM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-oIE6p-E_m2w"
   },
   "outputs": [],
   "source": [
    "RF_Mode_IM = RandomForest_model(X_mode, y_mode, \"IM\")\n",
    "RF_Mode_IM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UtKGoYDce248"
   },
   "outputs": [],
   "source": [
    "RF_MICE_IM = RandomForest_model(X_mice, y_mice, \"IM\")\n",
    "RF_MICE_IM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v8mKeDTUwjPE"
   },
   "source": [
    "#### **TomekLinks**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RF_Unknown_TML = RandomForest_model(X_uk, X_uk, \"TomekLinks\")\n",
    "RF_Unknown_TML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FE2mZm7jBEq-"
   },
   "outputs": [],
   "source": [
    "RF_ML_TML = RandomForest_model(X_ml, y_ml, \"TomekLinks\")\n",
    "RF_ML_TML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TlTN8eYKCNgf"
   },
   "outputs": [],
   "source": [
    "RF_Mode_TML = RandomForest_model(X_mode, y_mode, \"TomekLinks\")\n",
    "RF_Mode_TML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J_mEqsuAfaWW"
   },
   "outputs": [],
   "source": [
    "RF_MICE_TML = RandomForest_model(X_mice, y_mice, \"TomekLinks\")\n",
    "RF_MICE_TML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q4zIMzKEv3pF"
   },
   "source": [
    "#### **SMOTE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RF_Unknown_SM = RandomForest_model(X_uk, X_uk, \"SMOTE\")\n",
    "RF_Unknown_SM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CmR4qcZ_CalH"
   },
   "outputs": [],
   "source": [
    "RF_ML_SM = RandomForest_model(X_ml, y_ml, \"SMOTE\")\n",
    "RF_ML_SM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m69my1EJCbwa"
   },
   "outputs": [],
   "source": [
    "RF_Mode_SM = RandomForest_model(X_mode, y_mode, \"SMOTE\")\n",
    "RF_Mode_SM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hi31LzW_fggZ"
   },
   "outputs": [],
   "source": [
    "RF_MICE_SM = RandomForest_model(X_mice, y_mice, \"SMOTE\")\n",
    "RF_MICE_SM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gnh0jOpfw8xP"
   },
   "source": [
    "#### **SMOTE + TomekLinks**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RF_Unknown_SMTML = RandomForest_model(X_uk, X_uk, \"SMOTETomek\")\n",
    "RF_Unknown_SMTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4jPncf6nCmDN"
   },
   "outputs": [],
   "source": [
    "RF_ML_SMTML = RandomForest_model(X_ml, y_ml, \"SMOTETomek\")\n",
    "RF_ML_SMTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-AeXeFWVCpvJ"
   },
   "outputs": [],
   "source": [
    "RF_Mode_SMTML = RandomForest_model(X_mode, y_mode, \"SMOTETomek\")\n",
    "RF_Mode_SMTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6wE3WKfZfl3H"
   },
   "outputs": [],
   "source": [
    "RF_MICE_SMTML = RandomForest_model(X_mice, y_mice, \"SMOTETomek\")\n",
    "RF_MICE_SMTML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oYuzQ1BvEUqv"
   },
   "source": [
    "## **Train Model with Support Vector Classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jGddWyXVOEAV"
   },
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pzNj_2vkM0R6"
   },
   "outputs": [],
   "source": [
    "def SVC_model(X, y, condition):\n",
    "    start_time = time.time()\n",
    "    n_splits = 5\n",
    "    numeric_cols = ['age', 'duration', 'campaign', 'pdays', 'previous',\n",
    "       'emp_variation_rate', 'cons_price', 'cons.conf.idx', 'euribor_3m',\n",
    "       'num_employees']\n",
    "\n",
    "    # numeric columns\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[('num', StandardScaler(), numeric_cols)], remainder='passthrough'\n",
    "    )\n",
    "\n",
    "    # pipeline\n",
    "    if condition == \"IM\":\n",
    "        pipeline = Pipeline([\n",
    "            ('preprocess', preprocessor),\n",
    "            ('svc', LinearSVC(class_weight= None, random_state=42))\n",
    "        ])\n",
    "\n",
    "    elif condition == \"SMOTE\":\n",
    "        pipeline = ImbPipeline([\n",
    "            ('smote', SMOTE(random_state=42)),\n",
    "            ('preprocess', preprocessor),\n",
    "            ('svc', LinearSVC(class_weight= None, random_state=42))\n",
    "        ])\n",
    "    elif condition == \"TomekLinks\":\n",
    "        pipeline = ImbPipeline([\n",
    "            ('under', TomekLinks()),\n",
    "            ('preprocess', preprocessor),\n",
    "            ('svc', LinearSVC(class_weight= None, random_state=42))\n",
    "        ])\n",
    "    elif condition == \"SMOTETomek\":\n",
    "        pipeline = ImbPipeline([\n",
    "            ('resample', SMOTETomek(random_state=42)),\n",
    "            ('preprocess', preprocessor),\n",
    "            ('svc', LinearSVC(class_weight= None, random_state=42))\n",
    "        ])\n",
    "\n",
    "    param_grid = {\n",
    "        'svc__C': [0.01, 0.1, 1, 10],\n",
    "        'svc__penalty': ['l2']\n",
    "    }\n",
    "\n",
    "    outer_cv = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    inner_cv = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "    accuracies, aucs, conf_matrixs = [], [], []\n",
    "    macro_f1s, macro_precisions, macro_recalls = [], [], []\n",
    "    weighted_f1s, weighted_precisions, weighted_recalls = [], [], []\n",
    "    sensitivities, specificities, balanced_accuracies = [], [], []\n",
    "\n",
    "    for fold_idx, (train_idx, test_idx) in enumerate(outer_cv.split(X, y), start=1):\n",
    "        X_train, X_val = X.iloc[train_idx], X.iloc[test_idx]\n",
    "        y_train, y_val = y.iloc[train_idx], y.iloc[test_idx]\n",
    "\n",
    "        grid_search = GridSearchCV(\n",
    "            estimator=clone(pipeline),\n",
    "            param_grid=param_grid,\n",
    "            cv=inner_cv,\n",
    "            scoring=\"f1\",\n",
    "            n_jobs=-1\n",
    "        )\n",
    "        grid_search.fit(X_train, y_train)\n",
    "        best_model = grid_search.best_estimator_\n",
    "\n",
    "        y_pred = best_model.predict(X_val)\n",
    "        y_scores = best_model.decision_function(X_val)  # LinearSVC\n",
    "\n",
    "        cm = confusion_matrix(y_val, y_pred)\n",
    "        conf_matrixs.append({\"fold\": fold_idx, \"conf_matrix\": cm})\n",
    "\n",
    "        # Print report\n",
    "        print(f\"\\n=== Classification Report for Fold {fold_idx} ===\")\n",
    "        print(classification_report(y_val, y_pred))\n",
    "\n",
    "        print(f\"Confusion Matrix for Fold {fold_idx}:\")\n",
    "        print(conf_matrixs[fold_idx-1]['conf_matrix'])\n",
    "        \n",
    "        print(f\"Best Parameters for Fold {fold_idx}: {grid_search.best_params_}\")\n",
    "\n",
    "        accuracies.append(accuracy_score(y_val, y_pred))\n",
    "        aucs.append(roc_auc_score(y_val, y_scores))\n",
    "        macro_f1s.append(f1_score(y_val, y_pred, average='macro'))\n",
    "        macro_precisions.append(precision_score(y_val, y_pred, average='macro'))\n",
    "        macro_recalls.append(recall_score(y_val, y_pred, average='macro'))\n",
    "        weighted_f1s.append(f1_score(y_val, y_pred, average='weighted'))\n",
    "        weighted_precisions.append(precision_score(y_val, y_pred, average='weighted'))\n",
    "        weighted_recalls.append(recall_score(y_val, y_pred, average='weighted'))\n",
    "\n",
    "        sensitivity = recall_score(y_val, y_pred, pos_label=1)\n",
    "        specificity = recall_score(y_val, y_pred, pos_label=0)\n",
    "        balanced_acc = (sensitivity + specificity) / 2\n",
    "\n",
    "        sensitivities.append(sensitivity)\n",
    "        specificities.append(specificity)\n",
    "        balanced_accuracies.append(balanced_acc)\n",
    "\n",
    "    results = {\n",
    "        'mean_accuracy': np.mean(accuracies),\n",
    "        'mean_auc': np.mean(aucs),\n",
    "        'macro_f1': np.mean(macro_f1s),\n",
    "        'macro_precision': np.mean(macro_precisions),\n",
    "        'macro_recall': np.mean(macro_recalls),\n",
    "        'weighted_f1': np.mean(weighted_f1s),\n",
    "        'weighted_precision': np.mean(weighted_precisions),\n",
    "        'weighted_recall': np.mean(weighted_recalls),\n",
    "        'mean_sensitivity': np.mean(sensitivities),\n",
    "        'mean_specificity': np.mean(specificities),\n",
    "        'mean_balanced_accuracy': np.mean(balanced_accuracies)\n",
    "    }\n",
    "\n",
    "    end_time = time.time()\n",
    "    print(f\"\\nTotal training time: {end_time - start_time:.2f} seconds\")\n",
    "\n",
    "    return pd.DataFrame([results])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ev0aO_g5Nu0a"
   },
   "source": [
    "#### **Imbalanced data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVC_ML_IM = SVC_model(X_ml, y_ml, \"IM\")\n",
    "SVC_ML_IM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVC_Mode_IM = SVC_model(X_mode, y_mode, \"IM\")\n",
    "SVC_Mode_IM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVC_MICE_IM = SVC_model(X_mice, y_mice, \"IM\")\n",
    "SVC_MICE_IM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zelT7cU7Nrvv"
   },
   "source": [
    "#### **TomekLinks**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CelvBP8eNrv0"
   },
   "outputs": [],
   "source": [
    "SVC_ML_TML = SVC_model(X_ml, y_ml, \"TomekLinks\")\n",
    "SVC_ML_TML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nIaMH8pANrv1"
   },
   "outputs": [],
   "source": [
    "SVC_Mode_TML = SVC_model(X_mode, y_mode, \"TomekLinks\")\n",
    "SVC_Mode_TML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVC_MICE_TML = SVC_model(X_mice, y_mice, \"TomekLinks\")\n",
    "SVC_MICE_TML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xDu8-UPWNojD"
   },
   "source": [
    "#### **SMOTE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JGck0txdNojG"
   },
   "outputs": [],
   "source": [
    "SVC_ML_SM = SVC_model(X_ml, y_ml, \"SMOTE\")\n",
    "SVC_ML_SM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k057-PKANojH"
   },
   "outputs": [],
   "source": [
    "SVC_Mode_SM = SVC_model(X_mode, y_mode, \"SMOTE\")\n",
    "SVC_Mode_SM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVC_MICE_SM = SVC_model(X_mice, y_mice, \"SMOTE\")\n",
    "SVC_MICE_SM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RmUVq4Q1NdzY"
   },
   "source": [
    "#### **SMOTE + TomekLinks**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Tv6WncYANdzh"
   },
   "outputs": [],
   "source": [
    "SVC_ML_SMTM = SVC_model(X_ml, y_ml, \"SMOTETomek\")\n",
    "SVC_ML_SMTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x0GYe6TnNdzi"
   },
   "outputs": [],
   "source": [
    "SVC_Mode_SMTM = SVC_model(X_mode, y_mode, \"SMOTETomek\")\n",
    "SVC_Mode_SMTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AXCuIgzCXwnn"
   },
   "outputs": [],
   "source": [
    "SVC_MICE_SMTM = SVC_model(X_mice, y_mice, \"SMOTETomek\")\n",
    "SVC_MICE_SMTM"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "pSgW4KftHQQT",
    "Lq_ezdbxxVcO",
    "oYuzQ1BvEUqv",
    "P2TS04zJK_Fp",
    "CVAclVlipnvA"
   ],
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
